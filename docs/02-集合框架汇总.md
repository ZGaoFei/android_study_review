## 集合框架汇总

### 数组

```
数组和集合的区别：
1、数组长度不可改变，而且无法保存具有映射关系的数据；集合类用于保存数量不确定的数据和具有映射关系的数据
2、数组元素可以是基本类型的值，也可以是对象；集合只能保存对象。
```

### Collection

> Collection 派生出List、Set、Queue三个子类

### List

> List 代表了有序可重复集合，可以根据元素的索引来访问

### ArrayList

```
ArrayList是List接口的大小可变数组的实现；
ArrayList允许null元素；
ArrayList的容量可以自动增长；
ArrayList不是同步的；
ArrayList的iterator和listIterator方法返回的迭代器是fail-fast的

ArrayList由于是数组实现，所以查询速度快，删除和插入较慢，因为需要移动数据
ArrayList在无参数初始化时，默认为一个空的数组，在第一次add()操作的时候才会生成一个长度为10的数组
扩容操作为：oldCapacity + (oldCapacity >> 1)，表示原先的容量/2+原先的容量，原先的1.5倍
remove()：实际是移动覆盖掉数据，将最后的元素置为空
clear()：将数组中所有元素置为null，size为0
add()：size加1，然后判断数组是否放的下，放不下则进行扩容
trimToSize()：将数组大小变为size的长度

modCount：可以用来检测快速失败的一种标志
Arrays.copyOf()执行的深拷贝
```

### LinkedList

```
允许null元素
不是同步的

LinkedList内部由链表实现，实际是一个双向循环链表，所以在插入和删除比较快，在访问比较慢，因为需要遍历
LinkedList内部实现是Node，Node包含了prev和next和item
get()：会根据当前index和链表的长度进行对比，如果大于链表长度的一半，则后序遍历，小于则前序遍历
可以用LinkedList来实现栈和队列的功能
LinkedList包含有first和last节点，first是一个空节点不保存数据，当创建一个LinkedList时，会将first的首位进行赋值，自身形成一个闭环

和ArrayList比较，删除和插入比ArrayList快，查询比ArrayList慢
```

### Set

> Set 代表无序不可重复集合，只能根据元素本身来访问

### HashSet

```
HashSet内部由HashMap的key来实现的，value是Object对象
利用HashMap的key的唯一性
```

### TreeSet

```java
TreeSet内部由TreeMap的key来实现的，value是Object对象
利用TreeMap的key具有排序性和唯一性
```

### Queue

> Queue 是队列集合

### Map

> Map 代表存储key-value对的集合，可以根据key来访问value，hash函数设计的优劣直接影响整体的性能
>
> 哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式

### HashMap

```
JDK1.7
HashMap内部由数组+链表实现，用链表来处理hash冲突
最坏的情况是，所有的key的hash值都是相同的，则由数组变成了一个链表，查找的效率从O(1)变成了O(n)，平均查找为O(n)/2
1.8中当链表的数据足够长的时候变成红黑树，查找的效率则变为了O(logn)

inflateTable()：为数组分配存储空间的
roundUpToPowerOf2()：可以确保capacity为大于或等于toSize的最接近toSize的二次幂
计算应该存在的数组位置：hash&(length-1) = hash % length，但是取模操作比较耗时，所以改为&操作
之所以数组的长度总是2的次幂，是因为在2的次幂的情况下，hash&(length-1) = hash % length等式成立
hash值 和 (length-1)按位与，使用length-1的意义在于，length是2的倍数，所以length-1在二进制来说每位都是1，这样可以保证最大的程度的散列hash值，否则，当有一位是0时，不管hash值对应位是1还是0，按位与后的结果都是0，会造成散列结果的重复。


put()：插入新数据到链表时使用的头插法

resize()：扩容操作
	把原tab中的Node节点使用头插法，新table中链表的顺序和旧列表中是相反的，在HashMap线程不安全的情况下，这种头插法可能会导致环状节点。每个节点都会重新计算在数组中的位置，如果出现hash冲突则采用头插法，将后加入的节点放在前面。
```

```
JDK1.8
HashMap内部由数组+链表+红黑树实现，数组存储的是一个链表数据，当发生hash冲突时（即key的hash值相同），会用链表和红黑树来保存
在常规构造器中，没有为数组table分配内存空间（有一个入参为指定Map的构造器例外），而是在执行put操作的时候才真正构建table数组
HashMap最多允许一个键值对的key为null，并且是线程不安全的和无序的

TREEIFY_THRESHOLD = 8：当链表长度大于8时，转换成红黑树
UNTREEIFY_THRESHOLD = 6：红黑树长度小于等于6时，转换成链表
threshold：阀值 = capacity（容量，默认为16）*loadFactory，扩容会参考这个值
loadFactor：负载因子也叫填充比，默认是0.75，加载因子可以自己指定，如果关注内存使用率可以设置大一些，如果关注查找效率可以设置小一点。加载因子设置接近1时，数组会在接近存储满才会扩容，可能导致每个桶里面的链表或者红黑树过长，虽然增加了内存使用率，但是会导致查询效率变低。加载因子设置较小时，会导致数组的扩容频率增加，导致内存浪费，但是会让数据更均匀的分布在数组上，增加了查询效率。0.75达到了在时间和空间上的平衡

get()：tab[(n - 1) & hash]，通过(n - 1) & hash获取数据在数组的位置，然后获取数组当前位置的值，如果当前位置的值key相同时，直接返回，如果不相等，则判断是链表或者红黑树，则遍历查找数据，hash值相同，key相同

put()：通过(n - 1) & hash获取数据在数组的位置，如果当前位置为空，直接放入，如果不为空，则将数据放入链表或者红黑树中，有可能会发生链表转换成红黑树的操作。如果链表的长度达到了8个，然后判断数组的长度，如果数组的长度不足64，则只进行扩容操作，如果超过64则将链表转换成红黑树
插入新数据到链表时使用的尾插法

扩容：
	第一种：使用默认构造方法初始化HashMap。HashMap在一开始初始化的时候会返回一个空的table，并且thershold为0。因此第一次扩容的容量为默认值DEFAULT_INITIAL_CAPACITY也就是16。同时threshold = DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR = 12。
	第二种：指定初始容量的构造方法初始化HashMap。初始容量会等于threshold，接着threshold = 当前的容量（threshold） * DEFAULT_LOAD_FACTOR。
	第三种：HashMap不是第一次扩容。如果HashMap已经扩容过的话，那么每次table的容量以及threshold量为原有的两倍。
    这边也可以引申到一个问题HashMap是先插入还是先扩容：HashMap初始化后首次插入数据时，先发生resize扩容再插入数据，之后每当插入的数据个数达到threshold时就会发生resize，此时是先插入数据再resize。
  
resize()：扩容操作，新数组是旧数组的2倍
    正常情况下，计算节点在table中的下标的方法是：hash&(oldTable.length-1)，扩容之后，table长度翻倍，计算table下标的方法是hash&(newTable.length-1)，也就是hash&(oldTable.length*2-1)，于是我们有了这样的结论：这新旧两次计算下标的结果，要不然就相同，要不然就是新下标等于旧下标加上旧数组的长度。
    在遍历链表节点的时候，会重新计算每个链表节点在新数组中的位置，链表节点在新数组中的位置要么为原来的位置，要么为原来的位置加上旧数组的长度，因此在遍历链表节点时候实际是将原来的链表分成了两个链表，然后放入新的数组中。
    在遍历红黑树节点的时候，会重新计算每个红黑树节点在新数组中的位置，红黑树节点在新数组中的位置要么为原来的位置，要么为原来的位置加上旧数组的长度，因此在遍历红黑树节点时候实际是将原来的红黑树分成了两个链表，然后放入新的数组中。分成的两个链表在最后会判断长度是否大于6，如果大于6则转换成红黑树，如果小于等于6则将树转换成链表

(n - 1) & hash：
例如：n=16，n-1=15，二进制为1111，扩容到n=32，n-1=31，二进制位11111，如果老数组的h的最左边一位为0，就可以保证新数组的位置与老数组一致，因此直接用(e.hash & oldCap)来判断最后一位是否为0
主干数组的长度一定是2的次幂，因此低位都为1，会使得获得的数组索引index更加均匀，否则，当有一位是0时，不管hash值对应位是1还是0，按位与后的结果都是0，会造成散列结果的重复。之所以数组的长度总是2的次幂，是因为在2的次幂的情况下，hash&(length-1) = hash % length等式成立，取模操作比较耗时，所以改为与操作，提高性能

tableSizeFor()：在指定初始化长度的时候，获取大于当前初始化长度最近的2的次幂作为阀值

hashCode()：(h = key.hashCode()) ^ (h >>> 16) hash的目的是为了尽量分布均匀。
取模做位与运算的时候，实际上刚刚开始数组的长度一般比较小，只利用了低16位,高16位是用不到的。这种情况下，产生hash冲突的概率会大大增加。这样设计保证了对象的hashCode的高16位的变化能反应到低16位中，相比较而言减少了hash冲突的情况 
选用^的方式是因为&和|都会使得结果偏向0或者1 ,并不是均匀的概念。
^：相同为0，不同为1

为什么选择6/8来作为链表转化为红黑树和红黑树转化为链表的值？
1、一般情况下，如果hashcode的分布离散很好的话，一般用不上红黑树，因为每个值都分布均匀，很少出现链表过长的情况，链表分布符合泊松分布，当长度为8的时候，概率已经非常小
2、只有长度>=7的时候，链表的平均查找时长lgn才小于链表的评价查找时长n/2，在冲突过多时，可以提高查找效率，为6才将红黑树转化为链表，是为了避免频繁的红黑树转化为链表，转换也是需要资源的
```

**为什么 String, Interger 这样的 wrapper 类适合作为键?**  
因为 String 是不可变的，也是 final 的，而且已经重写了 equals() 和 hashCode() 方法了。其他的 wrapper（包装） 类也有这个特点。不可变性是必要的，因为为了要计算 hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的 hashcode 的话，那么就不能从 HashMap 中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个 field 声明成 final 就能保证 hashCode 是不变的，那么请这么做吧。因为获取对象的时候要用到 equals() 和 hashCode() 方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的 hashcode 的话，那么碰撞的几率就会小些，这样就能提高 HashMap 的性能。

[参考](https://blog.csdn.net/lkforce/article/details/89521318)

[Java集合之一—HashMap](https://blog.csdn.net/woshimaxiao1/article/details/83661464)

![JDK 8](../images/jdk8-hashmap.png)

### TreeMap

~~~
TreeMap提供了一种以排序顺序存储键/值对的有效方法。它是基于红黑树的NavigableMap实现。

它存储类似于HashMap的键值对。
它只允许不同的键。无法复制密钥。
它不能有null键但可以有多个null值。
它按排序顺序（自然顺序）或按Comparator Map创建时提供的密钥存储密钥。
它提供了有保证的log（n）的时间成本，为containsKey，get，put和remove操作。
它不同步。用于Collections.synchronizedSortedMap(new TreeMap())在并发环境中工作。
该iterator方法返回的迭代器是快速失败的。

TreeMap的key要么实现了Comparable接口，要么传入comparator，否则无法比较key的值来进行排序，导致崩溃
~~~

### HashTable

```
HashTable内部是由数组+链表实现，也是根据hash算法来确定数据保存的位置。由链表来解决hash冲突
初始容量是11，负载因子是0.75
HashTable是线程安全的
HashTable的key和value都不能为null

rehash()：执行数组扩容操作，并且重新计算数据的位置，放入新数组中
```

### LinkedHashMap

```
LinkedHashMap继承自HashMap，所以HashMap的功能它都具备
LinkedHashMap存储数据是交给了HashMap来存储，内部由一个链表来按顺序连接所有保存的数据，用链表来保证数据的顺序性。

LinkedHashMap正是因为HashMap与双向链表的存在，即可以使用HashMap提供的功能，也可以通过两种迭代方式进行循环遍历应对不同的需求场景(对于LinkedHashMap的迭代实际是对于双向链表的迭代，起为head尾为tail)：

第一种：按照插入（put）的顺序迭代(设置属性accessOrder=false)，双向链表中节点按照是插入的顺序保存

第二种：按照访问（get）的顺序迭代(设置属性accessOrder=true)，每次对该节点进行access操作都会使该节点移动到双向链表的尾部，所以基于此特点在此双向链表尾部的数据都是最近被访问的。

LinkedHashMap还提供了一种淘汰数据的机制(由afterNodeInsertion方法提供)，该机制在满足一定条件情况(该条件由使用者定义，继承LinkedHashMap重写removeEldestEntry()方法)下触发。一旦达到触发条件，那么每进行一个写入操作都会移除双向链表head节点(因为head的数据是最早写入的也就是最早存在的这也是removeEldestEntry方法名的含义“移除年老实体”)。LinkedHashMap实现LRU算法的途径之一。
LRU：最近最久未使用算法
```

### ConcurrentHashMap

```
为什么使用ConcurrentHashMap？
因为HashMap在高并发情况下，里面的链表会形成死循环（首尾相连），导致CPU使用率达到接近100%
HashTable使用synchronize给每个方法加锁，性能低下

HashEntry是一个散列表（数组+链表）

JDK1.7 
采用分段锁的机制，实现并发的更新操作，底层由Segment数组和HashEntry数组组成。Segment继承ReentrantLock用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶。HashEntry 用来封装映射表的键 / 值对；每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。先在Segment数组中hash找到在数组中的位置，然后在Segment中HashEntry数组再次进行hash找到在HashEntry中的位置。

JDK1.8
采用synchronize + CAS + HashEntry + 红黑树实现
散列表+红黑树实现
支持高并发的访问和更新，它是线程安全的，加锁的粒度为数组保存的每个根节点
检索操作不用加锁，get方法是非阻塞的
key和value都不允许为null

取消segments字段，直接采用transient volatile HashEntry<K,V>[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。
将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。

扩容：
可以分配其他线程进行扩容

数据结构同HashMap，只是在对应的访问节点上添加了锁的机制，保证操作的安全性

CAS算法
CAS（比较与交换，Compare and swap） 是一种有名的无锁算法
CAS有3个操作数
	内存值V
	旧的预期值A
	要修改的新值B
	
当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做

当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值(A和内存值V相同时，将内存值V修改为B)，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试(否则什么都不做)
看了上面的描述应该就很容易理解了，先比较是否相等，如果相等则替换(CAS算法)

volatile关键字
volatile仅仅用来保证该变量对所有线程的可见性，但不保证原子性

保证该变量对所有线程的可见性
在多线程的环境下：当这个变量修改时，所有的线程都会知道该变量被修改了，也就是所谓的“可见性”

不保证原子性
修改变量(赋值)实质上是在JVM中分了好几步，而在这几步内(从装载变量到修改)，它是不安全的。
```

### ArrayMap

```
ArrayMap的原理，主要是利用了hashCode的唯一性且为int，将其有序的放入数组中，然后进行二分查找。
ArrayMap是一个<key,value>映射的数据结构，它设计上更多的是考虑内存的优化，内部是使用两个数组进行数据存储，一个数组记录key的hash值，另外一个数组记录key和Value值，它和SparseArray一样，也会对key使用二分法进行从小到大排序，在添加、删除、查找数据的时候都是先使用二分查找法得到相应的index，然后通过index来进行添加、查找、删除等操作，所以，应用场景和SparseArray的一样，如果在数据量比较大的情况下，那么它的性能将退化至少50%。

利用key的hash值为int，将其有序的放入keys数组中，在根据key获取数据时，先根据hash值通过二分查找法获取hash值在hashs数组中的位置index，然后在values数组中取出值

数组中默认为空数组，在put操作时才会去实例化数组

put():
	mHashes[index] = hash;
	mArray[index<<1] = key;
	mArray[(index<<1)+1] = value;
	可以看出来key的hash值单独存放一个数组里，key和value的值都是存放在values里面，values数组存储数据的格式为：key、value、key、value···，即第2*index保存的key，2*index+1保存的是value
	
remove():
	删除是将当前index后面的数据往前移动一位，覆盖到当前index的数据
	
indexOf():
	由于可能存在key不同hash值相同的情况，所以在获取key对应的位置时，会根据获取到的key的位置进行【前后】遍历（因为二分查找法获取到的位置只是相同数据中的某一个），比较key的值相同来获取对应的index值，首先在hashes数组中找到index，然后对比mArray[index<<1]与key是否相等，如不相等则从index+1开始向后遍历，如果还没有找到则从index-1向前遍历。

扩容：BASE_SIZE=4
n = osize >= (BASE_SIZE*2) ? (osize+(osize>>1)): (osize >= BASE_SIZE ? (BASE_SIZE*2) : BASE_SIZE);
	当数组长度大于4*2的时候，数组长度扩容为原来的1.5倍
	当数组长度不大于4*2，但是大于4的时候，变为4*2，否则为4
	
freeArrays()：
	当长度不够用，我们需要废弃掉老的数组，使用新的数组的时候，把老的数组（包含mHashes和mArray）的数据添加到oldArray当中，然后把oldArray赋值给mBaseCache（4个长度），如果再有新ArrayMap创建数组空间的时候，如果还是申请4个的空间，那么优先使用缓存下来的这个。
	同理，mTwiceBaseCache是缓存8个长度的数组空间的。
allocArrays()：
	如果数组长度为4或者8的时候优先使用缓存的数组

ArrayMap应用场景
1.数据量不大，最好在千级以内
2.数据结构类型为Map类型

假设数据量都在千级以内的情况下：
1、如果key的类型已经确定为int类型，那么使用SparseArray，因为它避免了自动装箱的过程，如果key为long类型，它还提供了一个LongSparseArray来确保key为long类型时的使用
2、如果key类型为其它的类型，则使用ArrayMap
```

### SparseArray

```
SparseArray用来保存key是int，value为Object的键值对
内部分别由两个数组来保存key和value，分别为int[]和Object[]，默认长度为10
int[] keys数组保存的所有的key值，并且是有序的，从小向大排序的，因此在使用查找的时候使用的二分查找法来提高查找效率
Object[] values数组保存value值，当保存数据时，先在keys数组中找到对应的index，然后将数据保存在values数组中
适用于比较少的数据

扩容：currentSize <= 4 ? 8 : currentSize * 2，小于等于4的时候扩容为8，否则扩大2倍

get()：先使用二分查找法找到key在keys数组中的index，然后获取values[index]的值

put()：先使用二分查找法找到key在keys中的index，如果index大于等于0，则直接赋值，如果小于0，表示没有这个key值，将index取反，获得key应该保存在数组的位置，如果当前位置的value值为DELETED则直接放入，否则会判断mGarbage为true或者保存的数据已经满了，则会进行gc操作，然后将数据插入到对应的数组中

remove()：移除一个元素，会mGarbage置为true，然后将values[index]置为DELETED状态

gc()：回收value为DELETED状态的数据，用后面的数据覆盖掉DELETED的数据

size()：如果mGarbage为true，会触发gc操作，返回保存的键值对个数

indexOf**()：如果mGarbage为true，会触发gc操作，返回key或者value所在的index

keyAt()：如果mGarbage为true，会触发gc操作，返回key所在index

valueAt()：如果mGarbage为true，会触发gc操作，返回value所在index

clear()：所有的value置为null的操作
```

### 数据结构的查询、插入效率对比

```
数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)

线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)

二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。

哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)
```



